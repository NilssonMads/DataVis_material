=== VisualComputingL08_3DGeometry.pdf pages=64
Visual Computing I:‚Ä® 
Interactive Computer Graphics and Vision
3D Geometry and Cameras Stefanie Zollmann and Tobias Langlotz 

Last time.. 
3
Homographies and Image Stitching
‚Ä¢ To stitch an image: 
‚Ä¢ Need to warp images to align 
‚Ä¢ This warping is a homography 
‚Ä¢ How to Ô¨Ånd the homography? 
‚Ä¢ If a feature at (u,v) in one image  matches to  (u‚Äô,v‚Äô) in the other, then
[
ùë¢‚Ä≤ 
ùë£‚Ä≤ 
1 ] ‚â°
h11 h12 h13
h21 h22 h23
h31 h32 h33
[
ùë¢
ùë£
1]

4
Do we still have a problem?
‚Ä¢ For each point we get constraints of the form: 
 
‚Ä¢ s and s are pixel values ‚Äì on the order of 100 or 1000 
‚Ä¢ So errors in  and  get multiplied by 1 
‚Ä¢ Errors in  and  get multiplied by 10,000 to 1,000,000 
‚Ä¢ This makes the solution very unstable 
[
0 0 0 ‚àíùë¢ùëñ ‚àíùë£ùëñ ‚àí1 ùë¢ùëñùë£‚Ä≤ ùëñ ùë£ùëñùë£‚Ä≤ ùëñ ùë£‚Ä≤ ùëñ
ùë¢ùëñ ùë£ùëñ 1 0 0 0 ‚àíùë¢ùëñùë¢‚Ä≤ ùëñ ‚àíùë£ùëñùë¢‚Ä≤ ùëñ ‚àíùë¢‚Ä≤ ùëñ]
h1
h2
‚ãÆ
h9
= [
0
0]
ùë¢ ùë£
h3 h6
h7 h8
5
Algorithm: Normalized DLT
Input:  correspondences 
Output: Homography, , such that 
1. Normalisation: Find  and  to centre  and 
 on the origin with average length 
2. Direct Linear Transform: 
1. Form the matrix  from  and 
2. Compute the SVD of , and find the smallest 
eigenvector, 
3. Reshape  to give the  homography matrix 
3. Denormalisation: Final solution is 
ùëõ ‚â• 4 ùêÆùëñ ‚Üî ùêÆ‚Ä≤ ùëñ
H ùêÆ‚Ä≤ ùëñ = HùêÆùëñ
T T‚Ä≤ 
~ùêÆùëñ = TùêÆùëñ~ùêÆ‚Ä≤ 
ùëñ = T‚Ä≤ ùêÆ‚Ä≤ ùëñ 2
A ~ùêÆùëñ ~ùêÆ‚Ä≤ 
ùëñ
A~ùê°~ùê° 3 √ó 3 ~H
H = T‚Ä≤ ‚àí1~HT
6
RANSAC for General Model Fitting
‚Ä¢ We need: 
‚Ä¢ A set of n points or items,  
‚Ä¢ To be able to Ô¨Åt a model, , to  points 
‚Ä¢ To Ô¨Ånd the distance,  
‚Ä¢ RANSAC has parameters: 
‚Ä¢ A threshold for acceptance 
‚Ä¢ A number of trials (see later) 
‚Ä¢RANSAC then proceeds as for the line fitting, except: 
‚Ä¢We select  items at random 
‚Ä¢We fit our model, , to them
ùëùùëñ
ùëÄ ùëò ‚â™ ¬†ùëõ
ùëë(ùëÄ, ¬†ùëùùëñ)
ùëò
ùëÄ
This time: 3D Geometry/Cameras 
8
Three Dimensions
‚Ä¢ We move from 2D to 3D 
‚Ä¢ Many ideas the same: 
‚Ä¢ Homogeneous co-ordinates 
‚Ä¢ Scaling and translation 
‚Ä¢ Some things get tricky 
‚Ä¢ Choice of left- or right- handed co-ordinates 
‚Ä¢ Rotations get complicated 
‚Ä¢ Projection from 3D to 2D

9
Left & Right-Handed Coordinates
Thumb is axis 
Forefinger is axis 
Middle finger is axis
Left handed Right-Handed

STEFANIE  ZOLLMANN 3D  Geometry 10
LEFT & RIGHT -HANDED CO-ORDINATES


=== VisualComputingL09_Calibration_Stereo.pdf pages=49
Visual Computing I:‚Ä® 
Interactive Computer Graphics and Vision
Camera Calibration and Stereo Vision Stefanie Zollmann and Tobias Langlotz 

Last time.. 
3
Three Dimensions
‚Ä¢ We moved from 2D to 3D 
‚Ä¢ Many ideas the same: 
‚Ä¢ Homogeneous co-ordinates 
‚Ä¢ Scaling and translation 
‚Ä¢ Some things get tricky 
‚Ä¢ Choice of left- or right-handed coordinates 
‚Ä¢ Rotations get complicated 
‚Ä¢ Projection from 3D to 2D

4
Left & Right-Handed Coordinates
Thumb is axis 
Forefinger is axis 
Middle finger is axis
Left handed Right-Handed

Separation slide
 ùëÖùëç =
cos(ùúÉ) ‚àísin(ùúÉ)
sin(ùúÉ) cos(ùúÉ)
0 0
0 0
0 0
0 0
1 0
0 1
https://szollmann.github.io/LectureExamples/tutorials/transformations/Transformations3DTeapot/
6
Quiz: Rotation in 3D

7
Quiz: Rotation in 3D

8
Quiz: Rotation in 3D

9
Quiz: Rotation in 3D

10
The Pinhole Camera Model and Projective Geometry
Z
f
U
X
(x, z)
(u, -f)
‚Ä¢ Removing the sign change
f
(u, f)
‚Ä¢ We can put the image plane 
in front of the pinhole 
‚Ä¢ Removes the sign 
change 
‚Ä¢ Not practical for real 
cameras 
‚Ä¢ The maths works out just 
Ô¨Åne 
[
ùë¢
ùë£
1] ‚â°
ùëì
0
0
0
ùëì
0
0
0
1
0
0
0
ùë•
ùë¶
ùëß
1

=== VisualComputingL10FundamentalMatrixDenseStereo.pdf pages=61
Visual Computing I:‚Ä® 
Interactive Computer Graphics and Vision
Stereo and Dense Depth Stefanie Zollmann and Tobias Langlotz 

Last time.. 
3
Camera Calibration
 
‚Ä¢  is a 2D image 
point 
‚Ä¢  is a  calibration matrix 
‚Ä¢  is a  rotation matrix 
‚Ä¢  is a 3D translation vector 
‚Ä¢  is a 3D point 
‚Ä¢ Camera calibration: determine 
ùêÆ ‚â° K[R ùê≠]ùê±
ùêÆ = [ùë¢ ùë£ 1]ùëá
K 3 √ó 3
R 3 √ó 3
ùê≠
ùê± = [ùë• ùë¶ ùëß 1]
ùëá
K

4
Calibration in OpenCV
‚Ä¢ Calibration targets: 
‚Ä¢ Input is 3D-2D matches 
‚Ä¢ Want easy-to Ô¨Ånd 2D points 
‚Ä¢ Need known 3D co-ordinates 
‚Ä¢ Planar targets common 
‚Ä¢ Easy to make with a printer 
‚Ä¢ Chess/Checkerboards 
‚Ä¢ Grids of dots or lines 
‚Ä¢ Is a 2D pattern enough?

5

How does a calibration look like? 
7
Do we need to calibrate our cameras for every app?
8
void Update() 
    { 
        // 1. Try to get the camera intrinsics 
        if (cameraManager.TryGetIntrinsics(out ARCameraIntrinsics intrinsics)) 
        { 
            // 2. The 'intrinsics' struct now holds the calibration data 
            // Access focal length (fx, fy) 
            Vector2 focalLength = intrinsics.focalLength; 
            // Access principal point (cx, cy) 
            Vector2 principalPoint = intrinsics.principalPoint; 
            // Access the image resolution this corresponds to 
            Vector2Int resolution = intrinsics.resolution; 
            // You now have all the components of the K matrix 
            // print($"Focal Length: {focalLength}, Principal Point: {principalPoint}"); 
             
            // You can construct the K matrix yourself if needed: 
            // Matrix4x4 K = Matrix4x4.identity; 
            // K[0, 0] = focalLength.x; 
            // K[1, 1] = focalLength.y; 
            // K[0, 2] = principalPoint.x; 
            // K[1, 2] = principalPoint.y; 
        } 
    } 
Accessing Intrinsics using ARCore
Simple Stereo 
A Simple Stereo System
10
‚Ä¢ Assume a set of 2 pinhole cameras 
 
‚Ä¢ Simplify for now:  
‚Ä¢ Camera 1 (C1): ,  
‚Ä¢ No rotation, looks along  
‚Ä¢ Camera 2 (C2): shifted along  
ùêÆ = K[R ùê≠]ùê±
K = I
R = I ùê≠ = ùüé
ùëç
ùëã
R = I, ¬†ùíï = [
ùëè
0
0] ùëã
ùëç
ùëå
ùëè
ùëà1
ùëâ1
ùëâ2
ùëà2
C1
C2

=== Visual Computing L11 SensingDepth.pdf pages=101
Visual Computing I: 
Interactive Computer Graphics and Vision
Practical Depth Sensing and Working with Range Data 
Stefanie Zollmann and Tobias Langlotz 

Last time.. 
The Fundamental Matrix
3
‚Ä¢ One way to express  is 
 
‚Ä¢ Here 
‚Ä¢  and  are the calibration matrices of the two cameras 
‚Ä¢  and  are the rotation and translation between them 
‚Ä¢  is the matrix form of the cross product with : 
F
F = K‚àíùëá
2 [ùê≠]√óRK‚àí1
1
K1 K2
R ùê≠
[ùê≠]√ó ùê≠
[t]√ó =
0 ‚àítz ty
tz 0 ‚àítx
‚àíty tx 0
Notes:
p1 = K1[I | 0]x
p2 = K2[R| t]x
The Essential Matrix
4
‚Ä¢ For calibrated cameras 
‚Ä¢ We can factor out  and  in   
‚Ä¢ This gives us the essential matrix 
 
‚Ä¢  has only Ô¨Åve DoF: 
‚Ä¢ 3 for 3D rotation 
‚Ä¢ 3 for 3D translation 
‚Ä¢ Less 1 for unknown scale
K1 K2 F = K‚àíùëá
2 [ùê≠]√óRK‚àí1
1
E = Kùëá
2 FK1 = [ùê≠]√óR
E

Stereo Rectification
5
I1 I2
I‚Äô1 I‚Äô2
X
Today: 
Practical Depth Sensing and Range Data 
Overview
7
‚Ä¢ Range Scanning 
‚Ä¢ Passive: 
‚Ä¢ Stereo or Multi-Camera 
‚Ä¢ Active: 
‚Ä¢ Structured Light Projection 
‚Ä¢ Optical Time-of-Flight 
‚Ä¢ Direct ToF 
‚Ä¢ Indirect ToF 
‚Ä¢ Registration of Depth Maps 
‚Ä¢ Processing Depth Maps

Range Scanning
8
‚Ä¢ Range sensors: 
‚Ä¢ Passive: >=2 cameras 
(stereovision) 
‚Ä¢ Active: >=1 cameras + >=1 
projectors (structured light) 
‚Ä¢ Result is depth information given as: 
‚Ä¢ Range image / depth map store 
depth at pixel positions from a 
speciÔ¨Åc view (RGBD image) 
‚Ä¢ A point cloud is a 3D dataset of 
discrete (X,Y,Z) surface points 
 Depth	Map Point	cloud
Passive Range Scanning  
10
‚Ä¢ Two or more cameras 
‚Ä¢ Stereo camera 
‚Ä¢ Two cameras 
‚Ä¢ One camera takes several photos from 
different perspectives 
‚Ä¢ Multiple cameras 
‚Ä¢ Which one is the easiest and why?
Passive Range Scanning
Camera	C1 Camera	C2Camera	C1


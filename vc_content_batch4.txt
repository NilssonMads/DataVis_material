=== VisualComputingL12Multiview.pdf pages=79
Visual Computing I:â€¨ 
Interactive Computer Graphics and Vision
Depth Maps Processing, 3D Reconstruction Stefanie Zollmann and Tobias Langlotz 

Last time.. 
Overview
3
â€¢ Range Scanning 
â€¢ Passive: 
â€¢ Stereo or Multi-Camera 
â€¢ Active: 
â€¢ Structured Light Projection 
â€¢ Optical Time-of-Flight 
â€¢ Direct ToF 
â€¢ Indirect ToF 
â€¢ Registration of Depth Maps 
â€¢ Processing Depth Maps

Passive Range Scanning
4
Camera C1 Camera C3
Camera C2
â€¢ Two or more cameras 
â€¢ Stereo camera 
â€¢ Two cameras 
â€¢ One camera takes several photos from 
different perspectives 
â€¢ Multiple cameras 
â€¢ Which one is the easiest and why? 
â€¢ What is the main challenge?
PointGrey Bumble Bee Zed Mini
Structured Light Projection
5
â€¢ Many structured light techniques exist that 
follow the two objectives: 
â€¢ Determine projector-camera 
correspondences with as few images as 
possible 
â€¢ Be robust against surface modulation and 
noise 
â€¢ Codes include: 
â€¢ Binary codes, such as the Gray code (most 
common): <100 images, quite robust 
â€¢ Intensity codes that apply cosine patterns 
and phase shifts: 6 images, but are not 
robust against strong absorptions 
â€¢ Color coding: <3 images, but very fragile 
(does not work on coloured surfaces)
Camera C Projector P
Optical Time-of-Flight (ToF) 
6
â€¢ Use low-power IR illumination for 
pulsed illumination 
â€¢ Can be switched on/off with <1ns 
â€¢ Generates a â€œlight wallâ€ that is 
reï¬‚ected back by objects
Illuminator ToF Sensor
â€¢ General idea: 
â€¢ Compute depth by round-trip 
estimation of a light wave emitted 
and its reï¬‚ection back to the 
sensor 
â€¢ D = C â‹… Î”t/2
7
Depth from Mono / Depth Estimation using ML
â€¢ Convolutional neural networks (CNNs) 
have been applied to monocular depth 
estimation 
â€¢ Common architectures include U-Net, 
ResNet, and DenseNet 
â€¢ During training:  
â€¢ Network is given pairs of images and 
their corresponding ground-truth depth 
maps 
â€¢ Minimize the difference between 
predicted depth and ground truth depth
https://github.com/yuhsuanyeh/BiFuse
Today: 
Processing of Depth Maps, Relative Pose 
and Multi-view Stereo
Overview
9
â€¢ Range Scanning 
â€¢ Passive: 
â€¢ Stereo or Multi-Camera 
â€¢ Active: 
â€¢ Structured Light Projection 
â€¢ Optical Time-of-Flight 
â€¢ Direct ToF 
â€¢ Indirect ToF 
â€¢ Registration of Depth Maps 
â€¢ Processing Depth Maps

Registration of Depth Maps

=== VisualComputingL13Recap.pdf pages=32
Visual Computing I:â€¨ 
Interactive Computer Graphics and Vision
3D Reconstruction/Recap Lecture Stefanie Zollmann and Tobias Langlotz 

Colmap Workflow
2
https://colmap.github.io/tutorial.html
Absolute Pose
Multi-View Stereo Pipeline
4
â€¢ Identify best matching pair 
â€¢ Two-view stereo for relative pose 
â€¢ Reconstruct 3D points 
â€¢ Minimise reprojection error 
â€¢ While still images to add 
â€¢ Select next best view 
â€¢ Determine absolute pose 
â€¢ Reconstruct more 3D points 
â€¢ Minimise reprojection error
Absolute Pose Problem
5
â€¢ We have a new image taken with a calibrated 
camera 
â€¢ We have already established a coordinate frame 
â€¢ We have 3D points and their corresponding 2D 
points from the ï¬rst image pair 
â€¢ We found matches from new image to ï¬rst image 
pair 
â€¢ Need to ï¬nd pose (rotation and translation) of the 
camera when the new image was taken
ð‘
ð‘‹
ð‘Œ
Perspective- -Point Pose (PnP)ð‘›
6
â€¢ Pose from 2D-3D matches 
â€¢ Have six unknowns ( ) 
â€¢ Each 2D-3D match  gives 
 
â€¢ How many matches? 
â€¢ Each point gives 3 equations 
â€¢ Adds 1 unknown ( ) 
â€¢  unknowns,  equations, 
 
R, Â ð­
ð®ð‘– â†” ð±ð‘–
ð‘˜ið®i = K[RÂ Â Â ð­]ð±ð‘–
ð‘˜ð‘–
6 + ð‘› 3ð‘›
n â‰¥ 3
ð‘
ð‘‹
ð‘Œð‘Œ
ð
ð‚
ð€
Perspective-3-Point Pose (P3P)
7
â€¢ Input: 
â€¢ The 3D coordinates of three known points in 
the world (e.g., landmarks) 
â€¢ The 2D coordinates of their projections in the 
camera image 
â€¢ The cameraâ€™s intrinsic calibration (focal length, 
principal point, etc.) 
â€¢ Output: 
â€¢ The rotation (camera orientation) 
â€¢ The translation (camera position) 
ð‘
ð‘‹
ð‘Œ
ð€ ð
ð‚
ðš ð›
ðœ
ð
ð‘Œ
ð
ð‚
Perspective-3-Point Pose (P3P)
8
â€¢ We have three 2D-3D matches 
â€¢ Call the 3D points , , and  
â€¢ The matching image points are , ,  
â€¢ The (unknown) camera location is  
â€¢ Overview of solution 
â€¢ Use angles between , , and  
â€¢ Find the distances , ,   
â€¢ This gives us equations for 
ð€ ð ð‚
ðš ð› ðœ
ð
â†’ðð€ â†’ðð â†’ðð‚
â†’ðð€ â†’ðð â†’ðð‚
ð
ð‘
ð‘‹
ð‘Œ
ð€ ð
ð‚
ðš ð›
ðœ
ð
ð‘Œ
ð
ð‚
Perspective-3-Point Pose (P3P)
9
â€¢ Deï¬ne the angles between rays
 
â€¢ Using dot products: 
 
ð›¼ = âˆ ðµð‘ƒð¶Â Â Â ð›½ = âˆ ð´ð‘ƒð¶Â Â ð›¾ = âˆ ð´ð‘ƒðµ
cosð›¼ = ð› â‹… ðœ
ð› ðœ
Â Â 
cosð›½ = ðš â‹… ðœ
ðš ðœ Â Â Â cosð›¾ = ðš â‹… ð’ƒ
ðš ð›
Â 
ð‘
ð‘‹
ð‘Œ
ð€ ð
ð‚
ðš ð›
ðœ
ð
ð›¼Î²
ð›¾
Perspective-3-Point Pose (P3P)
10
â€¢ The law of cosines tells us that 
 
 
 
â€¢ Solve for 
  and 
â†’ð€ð
2
= â†’ðð€
2
+ â†’ðð
2
âˆ’ 2 â†’ðð€ â†’ðð cosð›¾
â†’ð€ð‚
2
= â†’ðð€
2
+ â†’ðð‚
2
âˆ’ 2 â†’ðð€ â†’ðð‚ cosð›½
â†’ðð‚
2
= â†’ðð
2
+ â†’ðð‚
2
âˆ’ 2 â†’ðð â†’ðð‚ cosð›¼
â†’ðð€ , â†’ðð , â†’ðð‚
ð‘
ð‘‹
ð‘Œ
ð€ ð
ð‚
ðš ð›
ðœ
ð
ð›¼Î²
ð›¾

=== VisualComputingGraphicsIntro.pdf pages=49
Visual Computing I:â€¨ 
Interactive Computer Graphics and Vision
Computer Graphics Introduction Stefanie Zollmann and Tobias Langlotz 

Quiz
What to do with all this data?
3
Point Clouds 3D Mesh data
4
Why do we need real-time graphics?
Games
 Augmented 
Reality
 Virtual Reality
 Visualization
Real-Time Graphics
6
Real-Time Graphics
Demands: 
â€¢ Full HD at 60 Hz: 1920 Ã— 1080 Ã— 60 
Hz = 124 Mpx/s  
â€¢ Stereo x2 (computing two images) 
â€¢ In real-time 
â€¢ Capacities for additional computations 
How? 
â€¢ Hardware implementation: graphics 
processing unit GPU
By Shawn Knight - http://www.techspot.com/news/65328-amd-radeon-rx-480-benchmarks-bare-pcb-
photos.html, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=54979727

Real-Time Graphics
Based on rasterisation of graphic 
primitives:
â€¢ Points 
â€¢ Lines 
â€¢ Triangles 
â€¢ Implemented in hardware (GPU)
7
Points
 Lines
 Triangles
GPUs do Rasterisation
â€¢ Rasterisation 
â€¢ Computing for each triangle 
which pixel it covers  
â€¢ Triangle centric approach 
â€¢ Rasteriser processes one triangle 
at a time
8
GPU
 Graphics Pipeline
Primitives
For each triangle
For each pixel
Does triangle cover pixel 
Keep closest hit

Mapping Vision Concepts to Graphics
9
Vision              Graphics          
[R|t] View matrix
K Projection matrix 
Triangulated points Vertex buffer     
Reprojection        Rasterization     
Image               Framebuffer       
The math and data structures are equivalent -> only the implementation changes. 
Graphics Pipeline
â€¢ Input 
â€¢ Geometric model 
â€¢ Vertices, normals, texture coordinates 
â€¢ Lighting/shading model 
â€¢ Light positions 
â€¢ View point and virtual camera 
configuration 
â€¢ Output 
â€¢ Colour (and depth) per pixel on a screen
10
https://commons.wikimedia.org/wiki/File:Utah_teapot_simple.png

=== VisualComputingL14GraphicsIntro.pdf pages=72
Visual Computing I:â€¨ 
Interactive Computer Graphics and Vision
Computer Graphics Introduction Stefanie Zollmann and Tobias Langlotz 

3D Geometry

Stereo Vision/ Epipolar Geometry 

Stereo Vision: Fundamental Matrix

Depth Sensing

Multiview Geometry

Quiz
Computer Graphics
What to do with all this data?
9
Point Clouds 3D Mesh data
3-Min Discussion: 
Why not just keep doing what we did so far and use 
image processing tools to render our 3D models?
What challenges would you expect?


